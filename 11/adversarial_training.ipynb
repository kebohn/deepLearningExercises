{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "international-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import numpy\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f07946-beb4-401e-b2a4-7b66613f1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(torch.nn.Module):\n",
    "    def __init__(self, K, O): # K = hidden units / O = outputs\n",
    "        super(Convolutional, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5), stride=1, padding=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=self.conv1.out_channels, out_channels=32, kernel_size=(5,5), stride=1, padding=2)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        # fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(7*7*32, K, bias=True)\n",
    "        self.fc2 = torch.nn.Linear(K, O)\n",
    "        \n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        self.bn = torch.nn.BatchNorm2d(self.conv2.out_channels)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        a = self.activation(self.pool(self.conv1(x)))\n",
    "        # a = self.activation(self.bn(self.pool(self.conv2(a)))) with batch normalization\n",
    "        a = self.activation(self.pool(self.conv2(a)))\n",
    "        a = torch.flatten(a, 1)\n",
    "        return self.fc2(self.activation(self.fc1(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d0acda-9b64-42c0-9521-4d53626b5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adversarial = False\n",
    "train_with_noise = False\n",
    "\n",
    "filename = f\"Results_{'noise' if train_with_noise else 'adv' if train_adversarial else 'none'}_bn.txt\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "train_set = torchvision.datasets.MNIST(root=\"data/MNIST\",train=True, download=True,transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root=\"data/MNIST\",train=False, download=True,transform=transform)\n",
    "\n",
    "# loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size=100)\n",
    "\n",
    "network = Convolutional(50,10)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=network.parameters(),\n",
    "    lr = 1e-2, momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9338c18-be1b-4700-bae4-1a75e8d09469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGS(x, t, alpha=0.3):\n",
    "    x.requires_grad_(True) # we need the gradient for the input\n",
    "    network.zero_grad() # no remainings\n",
    "    z = network.forward(x)\n",
    "    J = loss(z, t)\n",
    "    J.backward()\n",
    "    grad = x.grad.detach() # get the gradient\n",
    "    return torch.clamp(x + alpha * torch.sign(grad), 0, 1) # perform gradient ascent [0,1]\n",
    "\n",
    "def noise(x, alpha=0.3):\n",
    "    noise = torch.bernoulli(torch.ones(x.shape) * 0.5) * 2 - 1\n",
    "    return torch.clamp(x + alpha * noise, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dec145-f0a1-454c-bdc2-0f7af0d0eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n",
      " Clean acc: 1135/10000 = 0.1135 \n",
      " Adver acc: 1135/1135 = 1.0000\n",
      "Epoch 2: \n",
      " Clean acc: 1135/10000 = 0.1135 \n",
      " Adver acc: 1135/1135 = 1.0000\n",
      "Epoch 3: \n",
      " Clean acc: 1490/10000 = 0.1490 \n",
      " Adver acc: 218/1490 = 0.1463\n",
      "Epoch 4: \n",
      " Clean acc: 6144/10000 = 0.6144 \n",
      " Adver acc: 255/6144 = 0.0415\n",
      "Epoch 5: \n",
      " Clean acc: 8441/10000 = 0.8441 \n",
      " Adver acc: 20/8441 = 0.0024\n",
      "Epoch 6: \n",
      " Clean acc: 8938/10000 = 0.8938 \n",
      " Adver acc: 17/8938 = 0.0019\n",
      "Epoch 7: \n",
      " Clean acc: 9196/10000 = 0.9196 \n",
      " Adver acc: 12/9196 = 0.0013\n",
      "Epoch 8: \n",
      " Clean acc: 9349/10000 = 0.9349 \n",
      " Adver acc: 18/9349 = 0.0019\n",
      "Epoch 9: \n",
      " Clean acc: 9458/10000 = 0.9458 \n",
      " Adver acc: 8/9458 = 0.0008\n",
      "Epoch 10: \n",
      " Clean acc: 9517/10000 = 0.9517 \n",
      " Adver acc: 18/9517 = 0.0019\n",
      "Epoch 11: \n",
      " Clean acc: 9577/10000 = 0.9577 \n",
      " Adver acc: 20/9577 = 0.0021\n",
      "Epoch 12: \n",
      " Clean acc: 9593/10000 = 0.9593 \n",
      " Adver acc: 23/9593 = 0.0024\n",
      "Epoch 13: \n",
      " Clean acc: 9652/10000 = 0.9652 \n",
      " Adver acc: 19/9652 = 0.0020\n",
      "Epoch 14: \n",
      " Clean acc: 9688/10000 = 0.9688 \n",
      " Adver acc: 30/9688 = 0.0031\n",
      "Epoch 15: \n",
      " Clean acc: 9708/10000 = 0.9708 \n",
      " Adver acc: 31/9708 = 0.0032\n",
      "Epoch 16: \n",
      " Clean acc: 9732/10000 = 0.9732 \n",
      " Adver acc: 31/9732 = 0.0032\n",
      "Epoch 17: \n",
      " Clean acc: 9751/10000 = 0.9751 \n",
      " Adver acc: 32/9751 = 0.0033\n",
      "Epoch 18: \n",
      " Clean acc: 9746/10000 = 0.9746 \n",
      " Adver acc: 27/9746 = 0.0028\n",
      "Epoch 19: \n",
      " Clean acc: 9783/10000 = 0.9783 \n",
      " Adver acc: 39/9783 = 0.0040\n",
      "Epoch 20: \n",
      " Clean acc: 9774/10000 = 0.9774 \n",
      " Adver acc: 33/9774 = 0.0034\n",
      "Epoch 21: \n",
      " Clean acc: 9793/10000 = 0.9793 \n",
      " Adver acc: 36/9793 = 0.0037\n",
      "Epoch 22: \n",
      " Clean acc: 9804/10000 = 0.9804 \n",
      " Adver acc: 46/9804 = 0.0047\n",
      "Epoch 23: \n",
      " Clean acc: 9802/10000 = 0.9802 \n",
      " Adver acc: 46/9802 = 0.0047\n",
      "Epoch 24: \n",
      " Clean acc: 9814/10000 = 0.9814 \n",
      " Adver acc: 47/9814 = 0.0048\n",
      "Epoch 25: \n",
      " Clean acc: 9817/10000 = 0.9817 \n",
      " Adver acc: 32/9817 = 0.0033\n",
      "Epoch 26: \n",
      " Clean acc: 9825/10000 = 0.9825 \n",
      " Adver acc: 42/9825 = 0.0043\n",
      "Epoch 27: \n",
      " Clean acc: 9832/10000 = 0.9832 \n",
      " Adver acc: 39/9832 = 0.0040\n",
      "Epoch 28: \n",
      " Clean acc: 9818/10000 = 0.9818 \n",
      " Adver acc: 42/9818 = 0.0043\n",
      "Epoch 29: \n",
      " Clean acc: 9841/10000 = 0.9841 \n",
      " Adver acc: 45/9841 = 0.0046\n",
      "Epoch 30: \n",
      " Clean acc: 9830/10000 = 0.9830 \n",
      " Adver acc: 50/9830 = 0.0051\n",
      "Epoch 31: \n",
      " Clean acc: 9843/10000 = 0.9843 \n",
      " Adver acc: 49/9843 = 0.0050\n",
      "Epoch 32: \n",
      " Clean acc: 9845/10000 = 0.9845 \n",
      " Adver acc: 49/9845 = 0.0050\n",
      "Epoch 33: \n",
      " Clean acc: 9848/10000 = 0.9848 \n",
      " Adver acc: 46/9848 = 0.0047\n",
      "Epoch 34: \n",
      " Clean acc: 9854/10000 = 0.9854 \n",
      " Adver acc: 60/9854 = 0.0061\n",
      "Epoch 35: \n",
      " Clean acc: 9855/10000 = 0.9855 \n",
      " Adver acc: 39/9855 = 0.0040\n",
      "Epoch 36: \n",
      " Clean acc: 9868/10000 = 0.9868 \n",
      " Adver acc: 51/9868 = 0.0052\n",
      "Epoch 37: \n",
      " Clean acc: 9853/10000 = 0.9853 \n",
      " Adver acc: 55/9853 = 0.0056\n",
      "Epoch 38: \n",
      " Clean acc: 9868/10000 = 0.9868 \n",
      " Adver acc: 56/9868 = 0.0057\n",
      "Epoch 39: \n",
      " Clean acc: 9870/10000 = 0.9870 \n",
      " Adver acc: 50/9870 = 0.0051\n",
      "Epoch 40: \n",
      " Clean acc: 9863/10000 = 0.9863 \n",
      " Adver acc: 39/9863 = 0.0040\n",
      "Epoch 41: \n",
      " Clean acc: 9874/10000 = 0.9874 \n",
      " Adver acc: 42/9874 = 0.0043\n",
      "Epoch 42: \n",
      " Clean acc: 9884/10000 = 0.9884 \n",
      " Adver acc: 40/9884 = 0.0040\n",
      "Epoch 43: \n",
      " Clean acc: 9878/10000 = 0.9878 \n",
      " Adver acc: 53/9878 = 0.0054\n",
      "Epoch 44: \n",
      " Clean acc: 9881/10000 = 0.9881 \n",
      " Adver acc: 44/9881 = 0.0045\n",
      "Epoch 45: \n",
      " Clean acc: 9877/10000 = 0.9877 \n",
      " Adver acc: 54/9877 = 0.0055\n",
      "Epoch 46: \n",
      " Clean acc: 9876/10000 = 0.9876 \n",
      " Adver acc: 36/9876 = 0.0036\n",
      "Epoch 47: \n",
      " Clean acc: 9883/10000 = 0.9883 \n",
      " Adver acc: 53/9883 = 0.0054\n",
      "Epoch 48: \n",
      " Clean acc: 9889/10000 = 0.9889 \n",
      " Adver acc: 37/9889 = 0.0037\n",
      "Epoch 49: \n",
      " Clean acc: 9887/10000 = 0.9887 \n",
      " Adver acc: 38/9887 = 0.0038\n",
      "Epoch 50: \n",
      " Clean acc: 9888/10000 = 0.9888 \n",
      " Adver acc: 38/9888 = 0.0038\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "for epoch in range(50):\n",
    "    for x, t in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = network(x)\n",
    "        J = loss(z, t)\n",
    "        J.backward()\n",
    "        \n",
    "        if train_adversarial:\n",
    "            x_hat = noise(x) if train_with_noise else FGS(x, t) # compute adversarials for batch\n",
    "            z_hat = network(x_hat) # output for adversarials\n",
    "            J = loss(z_hat, t)\n",
    "            J.backward()\n",
    "        optimizer.step() # perfom combined optimizer step\n",
    "        \n",
    "    # evalutation\n",
    "    correct_clean = 0\n",
    "    correct_adv = 0\n",
    "    for x, t in test_loader:\n",
    "        with torch.no_grad():\n",
    "            z = network(x)\n",
    "            # compute classification accuracy\n",
    "            correct = torch.argmax(z, dim=1) == t\n",
    "            correct_clean += torch.sum(correct)\n",
    "            \n",
    "        # create adversarial samples for correctly classified samples\n",
    "        x = x[correct]\n",
    "        t = t[correct]\n",
    "        x_hat = FGS(x, t)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z_hat = network(x_hat)\n",
    "            # compute classification accuracy\n",
    "            correct = torch.argmax(z_hat, dim=1) == t\n",
    "            correct_adv += torch.sum(correct)\n",
    "            \n",
    "    print(f\"Epoch {epoch+1}: \\n Clean acc: {correct_clean}/{len(test_set)} = {correct_clean.item()/len(test_set):.4f} \\n Adver acc: {correct_adv}/{correct_clean} = {correct_adv.item()/correct_clean.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
